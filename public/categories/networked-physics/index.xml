<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Networked Physics on Gaffer On Games</title>
    <link>http://173.255.195.190/gafferongames/categories/networked-physics/index.xml</link>
    <description>Recent content in Networked Physics on Gaffer On Games</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© The Network Protocol Company, Inc.</copyright>
    <atom:link href="http://173.255.195.190/gafferongames/categories/networked-physics/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Snapshot Compression</title>
      <link>http://173.255.195.190/gafferongames/post/snapshot_compression/</link>
      <pubDate>Sun, 04 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>http://173.255.195.190/gafferongames/post/snapshot_compression/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;http://173.255.195.190/gafferongames/about&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;http://173.255.195.190/gafferongames/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&#34;http://gafferongames.com/networked-physics/snapshots-and-interpolation/&#34;&gt;previous article&lt;/a&gt; we sent snapshots of the entire simulation 10 times per-second over the network and interpolated between them to reconstruct a view of the simulation on the other side.&lt;/p&gt;

&lt;p&gt;The problem with a low snapshot rate is that interpolation between snapshots adds interpolation delay on top of network latency. At 10 snapshots per-second, the minimum interpolation delay is 100ms, and a more practical minimum considering network jitter is 150ms. If protection against one or two lost packets in a row is desired, this blows out to 250ms or 350ms.&lt;/p&gt;

&lt;p&gt;This is not an acceptable amount of delay for most games, but when the physics simulation is as unpredictable as ours, the only way to reduce it is to increase the packet send rate. Unfortunately, increasing the send rate also increases bandwidth. So what we&amp;rsquo;re going to do in this article is work through every possible bandwidth optimization &lt;em&gt;(that I can think of at least)&lt;/em&gt; until we get bandwidth under control.&lt;/p&gt;

&lt;p&gt;Our target bandwidth is &lt;strong&gt;&lt;u&gt;256 kilobits per-second&lt;/u&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&#34;starting-point-60hz&#34;&gt;Starting Point @ 60HZ&lt;/h1&gt;

&lt;p&gt;Life is rarely easy, and the life of a network programmer, even less so. As network programmers we&amp;rsquo;re often tasked with the impossible, so in that spirit, let&amp;rsquo;s increase the snapshot send rate from 10 to 60 snapshots per-second and see exactly how far away we are from our target bandwidth.&lt;/p&gt;

&lt;video preload=&#34;auto&#34; controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_compression_uncompressed.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_compression_uncompressed.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;o_O&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s a &lt;em&gt;LOT&lt;/em&gt; of bandwidth: &lt;strong&gt;&lt;u&gt;17.37 megabits per-second!&lt;/u&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s break it down and see where all the bandwidth is going.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the state sent per-cube in the snapshot:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    struct CubeState
    {
        bool interacting;
        vec3f position;
        vec3f linear_velocity;
        quat4f orientation;
    };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here&amp;rsquo;s the size of each field sent over the network, uncompressed:&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;quat orientation: &lt;b&gt;128 bits&lt;/b&gt;&lt;/li&gt;
    &lt;li&gt;vec3 linear_velocity: &lt;b&gt;96 bits&lt;/b&gt;&lt;/li&gt;
    &lt;li&gt;vec3 position: &lt;b&gt;96 bits&lt;/b&gt;&lt;/li&gt;
    &lt;li&gt;bool interacting: &lt;b&gt;1 bit&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This gives a total of 321 bits bits per-cube (or 40.125 bytes per-cube).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do a quick calculation to see if the bandwidth checks out. The scene has 901 cubes so &lt;strong&gt;901*40.125 = 36152.625&lt;/strong&gt; bytes of cube data per-snapshot. 60 snapshots per-second so &lt;strong&gt;36152.625 * 60 = 2169157.5&lt;/strong&gt; bytes per-second. Add in packet header estimate: &lt;strong&gt;2169157.5 + 32*60 = 2170957.5&lt;/strong&gt;. Convert bytes per-second to megabits per-second: &lt;strong&gt;2170957.5 * 8 / ( 1000 * 1000 ) = 17.38mbps&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Everything checks out. There&amp;rsquo;s no easy way around this, we&amp;rsquo;re sending a hell of a lot of bandwidth, and we have to reduce that to something around 1-2% of it&amp;rsquo;s current bandwidth to hit our target of 256 kilobits per-second.&lt;/p&gt;

&lt;p&gt;Is this even possible? &lt;em&gt;Of course it is!&lt;/em&gt; Let&amp;rsquo;s get started :)&lt;/p&gt;

&lt;h2 id=&#34;optimizing-orientation&#34;&gt;Optimizing Orientation&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll start by optimizing orientation because it&amp;rsquo;s the largest field. (When optimizing bandwidth it&amp;rsquo;s good to work in the order of greatest to least potential gain where possible&amp;hellip;)&lt;/p&gt;

&lt;p&gt;Many people when compressing a quaternion think: &amp;ldquo;I know. I&amp;rsquo;ll just pack it into 8.8.8.8 with one 8 bit signed integer per-component!&amp;rdquo;. Sure, that works, but with a bit of math you can get much better accuracy with fewer bits using a trick called the &amp;ldquo;smallest three&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;How does the smallest three work? Since we know the quaternion represents a rotation its length must be 1, so x^2+y^2+z^2+w^2 = 1. We can use this identity to drop one component and reconstruct it on the other side. For example, if you send x,y,z you can reconstruct w = sqrt( 1 - x^2 - y^2 - z^2 ). You might think you need to send a sign bit for w in case it is negative, but you don&amp;rsquo;t, because you can make w always positive by negating the entire quaternion if w is negative (in quaternion space (x,y,z,w) and (-x,-y,-z,-w) represent the same rotation.)&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t always drop the same component due to numerical precision issues. Instead, find the component with the largest absolute value and encode its index using two bits [0,3] (0=x, 1=y, 2=z, 3=w), then send the index of the largest component and the smallest three components over the network (hence the name). On the other side use the index of the largest bit to know which component you have to reconstruct from the other three.&lt;/p&gt;

&lt;p&gt;One final improvement. If v is the absolute value of the largest quaternion component, the next largest possible component value occurs when two components have the same absolute value and the other two components are zero. The length of that quaternion (v,v,0,0) is 1, therefore v^2 + v^2 = 1, 2v^2 = 1, v = 1/sqrt(2). This means you can encode the smallest three components in [-0.707107,+0.707107] instead of [-1,+1] giving you more precision with the same number of bits.&lt;/p&gt;

&lt;p&gt;With this technique I&amp;rsquo;ve found that minimum sufficient precision for my simulation is 9 bits per-smallest component. This gives a result of 2 + 9 + 9 + 9 = 29 bits per-orientation (down from 128 bits).&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_orientation.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_orientation.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;This optimization reduces bandwidth by over 5 megabits per-second, and I think if you look at the right side, you&amp;rsquo;d be hard pressed to spot any artifacts from the compression.&lt;/p&gt;

&lt;h2 id=&#34;optimizing-linear-velocity&#34;&gt;Optimizing Linear Velocity&lt;/h2&gt;

&lt;p&gt;What should we optimize next? It&amp;rsquo;s a tie between linear velocity and position. Both are 96 bits. In my experience position is the harder quantity to compress so let&amp;rsquo;s start with linear velocity.&lt;/p&gt;

&lt;p&gt;To compress linear velocity we need to bound its x,y,z components in some range so we don&amp;rsquo;t need to send full float values. I found that a maximum speed of 32 meters per-second is a nice power of two and doesn&amp;rsquo;t negatively affect the player experience in the cube simulation. Since we&amp;rsquo;re really only using the linear velocity as a &lt;em&gt;hint&lt;/em&gt; to improve interpolation between position sample points we can be pretty rough with compression. 32 distinct values per-meter per-second provides acceptable precision.&lt;/p&gt;

&lt;p&gt;Linear velocity has been bounded and quantized and is now three integers in the range [-1024,1023]. That breaks down as follows: [-32,+31] (6 bits) for integer component and multiply 5 bits fraction precision. I hate messing around with sign bits so I just add 1024 to get the value in range [0,2047] and send that instead. To decode on receive just subtract 1024 to get back to signed integer range before converting to float.&lt;/p&gt;

&lt;p&gt;11 bits per-component gives 33 bits total per-linear velocity. Just over &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; the original uncompressed size!&lt;/p&gt;

&lt;p&gt;We can do even better than this because most cubes are stationary. To take advantage of this we just write a single bit &amp;ldquo;at rest&amp;rdquo;. If this bit is 1, then velocity is known zero and is not sent. Otherwise, the compressed velocity follows after the bit (33 bits). Cubes at rest now cost just 127 bits, while cubes that are moving cost one bit more than they previously did: 159 + 1 = 160 bits.&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_at_rest_flag.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_at_rest_flag.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;But why are we sending linear velocity at all? In the &lt;a href=&#34;http://gafferongames.com/networked-physics/snapshots-and-interpolation/&#34;&gt;previous article&lt;/a&gt; we decided to send it because it improved the quality of interpolation at 10 snapshots per-second, but now that we&amp;rsquo;re sending 60 snapshots per-second is this still necessary? As you can see below the answer is &lt;em&gt;no&lt;/em&gt;.&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_no_velocity.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_no_velocity.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Linear interpolation is good enough at 60HZ. This means we can avoid sending linear velocity entirely. Sometimes the best bandwidth optimizations aren&amp;rsquo;t about optimizing what you send, they&amp;rsquo;re about what you &lt;em&gt;don&amp;rsquo;t&lt;/em&gt; send.&lt;/p&gt;

&lt;h2 id=&#34;optimizing-position&#34;&gt;Optimizing Position&lt;/h2&gt;

&lt;p&gt;Now we have only position to compress. We&amp;rsquo;ll use the same trick we used for linear velocity: bound and quantize. I chose a position bound of [-256,255] meters in the horizontal plane (xy) and since in the cube simulation the floor is at z=0, I chose a range of [0,32] meters for z.&lt;/p&gt;

&lt;p&gt;Now we need to work out how much precision is required. With experimentation I found that 512 values per-meter (roughly 2mm precision) provides enough precision. This gives position x and y components in [-131072,+131071] and z components in range [0,16383]. That&amp;rsquo;s 18 bits for x, 18 bits for y and 14 bits for z giving a total of 50 bits per-position (originally 96).&lt;/p&gt;

&lt;p&gt;This reduces our cube state to 80 bits, or just 10 bytes per-cube.&lt;/p&gt;

&lt;p&gt;This is approximately &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt; of the original cost. Definite progress!&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compressed_position.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compressed_position.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Now that we&amp;rsquo;ve compressed position and orientation we&amp;rsquo;ve run out of simple optimizations. Any further reduction in precision results in unacceptable artifacts.&lt;/p&gt;

&lt;h2 id=&#34;delta-compression&#34;&gt;Delta Compression&lt;/h2&gt;

&lt;p&gt;Can we optimize further? The answer is yes, but only if we embrace a completely new technique: &lt;b&gt;&lt;u&gt;delta compression&lt;/u&gt;&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;Delta compression sounds mysterious. Magical. Hard. Actually, it&amp;rsquo;s not hard at all. Here&amp;rsquo;s how it works: the left side sends packets to the right like this: &amp;ldquo;This is snapshot 110 encoded relative to snapshot 100&amp;rdquo;. The snapshot being encoded relative to is called the baseline. How you do this encoding is up to you, there are many fancy tricks, but the basic, big order of magnitude win comes when you say: &amp;ldquo;Cube n in snapshot 110 is the same as the baseline. One bit: Not changed!&amp;ldquo;.&lt;/p&gt;

&lt;p&gt;To implement delta encoding it is of course essential that the sender only encodes snapshots relative to baselines that the other side has received, otherwise they cannot decode the snapshot. Therefore, to handle packet loss the receiver has to continually send &amp;ldquo;ack&amp;rdquo; packets back to the sender saying: &amp;ldquo;the most recent snapshot I have received is snapshot n&amp;rdquo;. The sender takes this most recent ack and if it is more recent than the previous ack updates the baseline snapshot to this value. The next time a packet is sent out the snapshot is encoded relative to this more recent baseline. This process happens continuously such that the steady state becomes the sender encoding snapshots relative to a baseline that is roughly RTT (round trip time) in the past.&lt;/p&gt;

&lt;p&gt;There is one slight wrinkle: for one round trip time past initial connection the sender doesn&amp;rsquo;t have any baseline to encode against because it hasn&amp;rsquo;t received an ack from the receiver yet. I handle this by adding a single flag to the packet that says: &amp;ldquo;this snapshot is encoded relative to the initial state of the simulation&amp;rdquo; which is known on both sides. Another option if the receiver doesn&amp;rsquo;t know the initial state is to send down the initial state using a non-delta encoded path, eg. as one large data block, and once that data block has been received delta encoded snapshots are sent first relative to the initial baseline in the data block, then eventually converge to the steady state of baselines at RTT.&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_delta_not_changed.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_delta_not_changed.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;As you can see above this is a big win. We can refine this approach and lock in more gains but we&amp;rsquo;re not going to get another order of magnitude improvement like this past this point. From now on we&amp;rsquo;re going to have to work pretty hard to get a number of small, cumulative gains to reach our goal of 256 kilobits per-second.&lt;/p&gt;

&lt;h2 id=&#34;incremental-improvements&#34;&gt;Incremental Improvements&lt;/h2&gt;

&lt;p&gt;First small improvement. Each cube that isn&amp;rsquo;t sent costs 1 bit (not changed). There are 901 cubes so we send 901 bits in each packet even if no cubes have changed. At 60 packets per-second this adds up to 54kbps of bandwidth. Seeing as there are usually significantly less than 901 changed cubes per-snapshot in the common case, we can reduce bandwidth by sending only changed cubes with a cube index [0,900] identifying which cube it is. To do this we need to add a 10 bit index per-cube to identify it.&lt;/p&gt;

&lt;p&gt;There is a cross-over point where it is actually more expensive to send indices than not-changed bits. With 10 bit indices, the cost of indexing is 10*n bits. Therefore it&amp;rsquo;s more efficient to use indices if we are sending 90 cubes or less (900 bits). We can evaluate this per-snapshot and send a single bit in the header indicating which encoding we are using: 0 = indexing, 1 = changed bits. This way we can use the most efficient encoding for the number of changed cubes in the snapshot.&lt;/p&gt;

&lt;p&gt;This reduces the steady state bandwidth when all objects are stationary to around 15 kilobits per-second. This bandwidth is composed entirely of our own packet header (uint16 sequence, uint16 base, bool initial) plus IP and UDP headers (28 bytes).&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_delta_relative_index.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_delta_relative_index.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Next small gain. What if we encoded the cube index relative to the previous cube index? Since we are iterating across and sending changed cube indices in-order: cube 0, cube 10, cube 11, 50, 52, 55 and so on we could easily encode the 2nd and remaining cube indices relative to the previous changed index, e.g.: +10, +1, +39, +2, +3. If we are smart about how we encode this index offset we should be able to, on average, represent a cube index with less than 10 bits.&lt;/p&gt;

&lt;p&gt;The best encoding depends on the set of objects you interact with. If you spend a lot of time moving horizontally while blowing cubes from the initial cube grid then you hit lots of +1s. If you move vertically from initial state you hit lots of +30s (sqrt(900)). What we need then is a general purpose encoding capable of representing statistically common index offsets with less bits.&lt;/p&gt;

&lt;p&gt;After a small amount of experimentation I came up with this simple encoding:&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;[1,8] =&amp;gt; 1 + 3 (4 bits)&lt;/li&gt;
    &lt;li&gt;[9,40] =&amp;gt; 1 + 1 + 5 (7 bits)&lt;/li&gt;
    &lt;li&gt;[41,900] =&amp;gt; 1 + 1 + 10 (12 bits)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notice how large relative offsets are actually more expensive than 10 bits. It&amp;rsquo;s a statistical game. The bet is that we&amp;rsquo;re going to get a much larger number of small offsets so that the win there cancels out the increased cost of large offsets. It works. With this encoding I was able to get an average of 5.5 bits per-relative index.&lt;/p&gt;

&lt;p&gt;Now we have a slight problem. We can no longer easily determine whether changed bits or relative indices are the best encoding. The solution I used is to run through a mock encoding of all changed cubes on packet write and count the number of bits required to encode relative indices. If the number of bits required is larger than 901, fallback to changed bits.&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_delta_relative_index.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_delta_relative_index.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Next small improvement. Encoding position relative to (offset from) the baseline position. Here there are a lot of different options. You can just do the obvious thing, eg. 1 bit relative position, and then say 8-10 bits per-component if all components have deltas within the range provided by those bits, otherwise send the absolute position (50 bits).&lt;/p&gt;

&lt;p&gt;This gives a decent encoding but we can do better. If you think about it then there will be situations where one position component is large but the others are small. It would be nice if we could take advantage of this and send these small components using less bits.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s a statistical game and the best selection of small and large ranges per-component depend on the data set. I couldn&amp;rsquo;t really tell looking at a noisy bandwidth meter if I was making any gains so I captured the position vs. position base data set and wrote it to a text file for analysis. The format is x,y,z,base_x,base_y,base_z with one cube per-line. The goal is to encode x,y,z relative to base x,y,z for each line. If you are interested, you can download this data set &lt;a href=&#34;http://gafferongames.com/wp-content/uploads/2015/02/position_values.txt&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I wrote a short ruby script to find the best encoding with a greedy search. The best bit-packed encoding I found for the data set works like this: 1 bit small per delta component followed by 5 bits if small [-16,+15] range, otherwise the delta component is in [-256,+255] range and is sent with 9 bits. If any component delta values are outside the large range, fallback to absolute position. Using this encoding I was able to obtain on average 26.1 bits for changed positions values.&lt;/p&gt;

&lt;h2 id=&#34;delta-encoding-smallest-three&#34;&gt;Delta Encoding Smallest Three&lt;/h2&gt;

&lt;p&gt;Next I figured that relative orientation would be a similar easy big win. Problem is that unlike position where the range of the position offset is quite small relative to the total position space, the change in orientation in 100ms is a much larger percentage of total quaternion space.&lt;/p&gt;

&lt;p&gt;I tried a bunch of stuff without good results. I tried encoding the 4D vector of the delta orientation directly and recomposing the largest component post delta using the same trick as smallest 3. I tried calculating the relative quaternion between orientation and base orientation, and since I knew that w would be large for this (rotation relative to identity) I could avoid sending 2 bits to identify the largest component, but in turn would need to send one bit for the sign of w because I don&amp;rsquo;t want to negate the quaternion. The best compression I could find using this scheme was only 90% of the smallest three. Not very good.&lt;/p&gt;

&lt;p&gt;I was about to give up but I run some analysis over the smallest three representation. I found that 90% of orientations in the smallest three format had the same largest component index as their base orientation 100ms ago. This meant that it could be profitable to delta encode the smallest three format directly. What&amp;rsquo;s more I found that there would be no additional precision loss with this method when reconstructing the orientation from its base. I exported the quaternion values from a typical run as a data set in smallest three format (available &lt;a href=&#34;http://gafferongames.com/wp-content/uploads/2015/02/smallest_three_values.txt&#34;&gt;here&lt;/a&gt;) and got to work trying the same multi-level small/large range per-component greedy search that I used for position.&lt;/p&gt;

&lt;p&gt;The best encoding found was: 5-8, meaning [-16,+15] small and [-128,+127] large. One final thing: as with position the large range can be extended a bit further by knowing that if the component value is not small the value cannot be in the [-16,+15] range. I leave the calculation of how to do this as an exercise for the reader. Be careful not to collapse two values onto zero.&lt;/p&gt;

&lt;p&gt;The end result is an average of 23.3 bits per-relative quaternion. That&amp;rsquo;s 80.3% of the absolute smallest three.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s just about it but there is one small win left. Doing one final analysis pass over the position and orientation data sets I noticed that 5% of positions are unchanged from the base position after being quantized to 0.5mm resolution, and 5% of orientations in smallest three format are also unchanged from base.&lt;/p&gt;

&lt;p&gt;These two probabilities are mutually exclusive, because if both are the same then the cube would be unchanged and therefore not sent, meaning a small statistical win exists for 10% of cube state if we send one bit for position changing, and one bit for orientation changing. Yes, 90% of cubes have 2 bits overhead added, but the 10% of cubes that save 20+ bits by sending 2 bits instead of 23.3 bit orientation or 26.1 bits position make up for that providing a small overall win of roughly 2 bits per-cube.&lt;/p&gt;

&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_delta_end_result.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/cubes_compression_delta_end_result.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;As you can see the end result is pretty good.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;And that&amp;rsquo;s about as far as I can take it using traditional hand-rolled bit-packing techniques. You can find source code for my implementation of all compression techniques mentioned in this article &lt;a href=&#34;https://gist.github.com/gafferongames/bb7e593ba1b05da35ab6&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s possible to get even better compression using a different approach. Bit-packing is inefficient because not all bit values have equal probability of 0 vs 1. No matter how hard you tune your bit-packer a context aware arithmetic encoding can beat your result by more accurately modeling the probability of values that occur in your data set. This &lt;a href=&#34;https://github.com/rygorous/gaffer_net/blob/master/main.cpp&#34;&gt;implementation&lt;/a&gt; by Fabian Giesen beat my best bit-packed result by 25%.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also possible to get a much better result for delta encoded orientations using the previous baseline orientation values to estimate angular velocity and predict future orientations rather than delta encoding the smallest three representation directly. Chris Doran from Geomerics wrote also wrote an excellent &lt;a href=&#34;http://www.geomerics.com/wp-content/uploads/2015/04/rotation_blog_toprint.pdf&#34;&gt;article&lt;/a&gt; exploring the mathematics of quaternion compression that is worth reading.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NEXT ARTICLE&lt;/strong&gt;: &lt;a href=&#34;http://gafferongames.com/networked-physics/state-synchronization/&#34;&gt;State Synchronization&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snapshots and Interpolation</title>
      <link>http://173.255.195.190/gafferongames/post/snapshots_and_interpolation/</link>
      <pubDate>Sun, 30 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://173.255.195.190/gafferongames/post/snapshots_and_interpolation/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;http://173.255.195.190/gafferongames/about&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;http://173.255.195.190/gafferongames/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&#34;http://gafferongames.com/networked-physics/deterministic-lockstep/&#34;&gt;previous article&lt;/a&gt; we networked a physics simulation using deterministic lockstep. Now, in this article we&amp;rsquo;re going to network the same simulation with a completely different technique: &lt;strong&gt;snapshot interpolation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Why a different technique? While deterministic lockstep is very efficient in terms of bandwidth, it&amp;rsquo;s not always possible to make your simulation deterministic. Also, as the player count increases, deterministic lockstep becomes problematic: you can&amp;rsquo;t simulate frame n until you receive input from &lt;em&gt;all&lt;/em&gt; players for that frame, so players end up waiting for the most lagged player. Because of this, I recommend deterministic lockstep for 2-4 players at most.&lt;/p&gt;

&lt;p&gt;If your simulation is not deterministic or you want higher player counts then you need a different technique. Snapshot interpolation fits the bill nicely. It is in many ways the polar opposite of deterministic lockstep: instead of running two simulations, one on the left and one on the right, and using synchronized inputs and perfect determinism to make sure they stay in perfectly in sync&amp;hellip; &lt;em&gt;with snapshot interpolation we don&amp;rsquo;t run any simulation on the right side at all!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;snapshots&#34;&gt;Snapshots&lt;/h2&gt;

&lt;p&gt;Instead, we capture a &lt;strong&gt;snapshot&lt;/strong&gt; of all relevant state from the simulation on the left and transmit it to the right, and on the right side, use those snapshots to reconstruct a visual approximation of the simulation, all without running the simulation itself.&lt;/p&gt;

&lt;p&gt;As a first pass, let&amp;rsquo;s send across the state required to render each cube:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    struct CubeState
    {
        bool interacting;
        vec3f position;
        quat4f orientation;
    };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m sure you&amp;rsquo;ve worked out by now that the cost of this technique is increased bandwidth usage. Greatly increased bandwidth usage. Hold on to your neckbeards, because a snapshot contains the visual state for the entire simulation. With a bit of math we can see that each cube serializes down to 225 bits or 28.1 bytes. Since there are 900 cubes in our simulation that means each snapshot is roughly 25 kilobytes. That&amp;rsquo;s pretty big!&lt;/p&gt;

&lt;p&gt;At this point I would like everybody to relax, take a deep breath, and imagine we live in a world where I can actually send a packet this large 60 times per-second over the internet and not have everything explode. Imagine I have FIOS &lt;em&gt;(I do)&lt;/em&gt;, or I&amp;rsquo;m sitting over a backbone link to another computer that is also on the backbone. Imagine I live in South Korea. Do whatever you need to do to suspend disbelief, but most of all, don&amp;rsquo;t worry, because I&amp;rsquo;m going to spend the entire next article showing you how to optimize snapshot bandwidth.&lt;/p&gt;

&lt;p&gt;When we send snapshot data in packets, we include at the top a 16 bit sequence number. This sequence number starts at zero and increases with each packet sent. We use this sequence number on receive to determine if the snapshot in a packet is newer or older than the most recent snapshot received. If it&amp;rsquo;s older then it&amp;rsquo;s thrown away.&lt;/p&gt;

&lt;p&gt;Each frame we just render the most recent snapshot received on the right:&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_60pps_jitter.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_60pps_jitter.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;Look closely though, and even though we&amp;rsquo;re sending the data as rapidly as possible (one packet per-frame) you can still see hitches on the right side. This is because the internet makes no guarantee that packets sent 60 times per-second nicely spaced 1/60th of a second apart. Packets are jittered. Some frames you receive two snapshot packets. Other frames you receive none.&lt;/p&gt;

&lt;h1 id=&#34;jitter-and-hitches&#34;&gt;Jitter and Hitches&lt;/h1&gt;

&lt;p&gt;This is actually a really common thing when you first start networking. You start out playing your game over LAN and notice you can just slam out packets really fast (60pps) and most of the time your game looks great because over the LAN those packets actually do tend to arrive at the same rate they were sent&amp;hellip; and then you start trying to play your game over wireless or the internet and you start seeing hitches. Don&amp;rsquo;t worry. There are ways to handle this!&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s look at how much bandwidth we&amp;rsquo;re sending with this naive approach. Each packet is 25312.5 bytes plus 28 bytes for IP + UDP header and 2 bytes for sequence number. That&amp;rsquo;s 25342.5 bytes per-packet and at 60 packets per-second this gives a total of 1520550 bytes per-second or 11.6 megabit/sec. Now there are certainly internet connections out there that can support that amount of traffic&amp;hellip; but since, let&amp;rsquo;s be honest, we&amp;rsquo;re not really getting a lot of benefit blasting packets out 60 times per-second with all the jitter, let&amp;rsquo;s pull it back a bit and send only 10 snapshots per-second:&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_no_interpolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_no_interpolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;You can see how this looks above. Not so great on the right side but at least we&amp;rsquo;ve reduced bandwidth by a factor of six to around 2 megabit/sec. We&amp;rsquo;re definitely headed in the right direction.&lt;/p&gt;

&lt;h2 id=&#34;linear-interpolation&#34;&gt;Linear Interpolation&lt;/h2&gt;

&lt;p&gt;Now for the trick with snapshots. What we do is instead of immediately rendering snapshot data received is that we buffer snapshots for a short amount of time in an interpolation buffer. This interpolation buffer holds on to snapshots for a period of time such that you have not only the snapshot you want to render but also, statistically speaking, you are very likely to have the next snapshot as well. Then as the right side moves forward in time we interpolate between the position and orientation for the two slightly delayed snapshots providing the illusion of smooth movement. In effect, we&amp;rsquo;ve traded a small amount of added latency for smoothness.&lt;/p&gt;

&lt;p&gt;You may be surprised at just how good it looks with linear interpolation @ 10pps:&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_linear_interpolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_linear_interpolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;Look closely though and you can see some artifacts on the right side. The first is a subtle position jitter when the player cube is hovering in the air. This is your brain detecting 1st order discontinuity at the sample points of position interpolation. The other artifact occurs when a bunch of cubes are in a katamari ball, you can see a sort of &amp;ldquo;pulsing&amp;rdquo; as the speed of rotation increases and decreases. This occurs because attached cubes interpolate linearly between two sample points rotating around the player cube, effectively interpolating &lt;em&gt;through&lt;/em&gt; the player cube as they take the shortest linear path between two points on a circle.&lt;/p&gt;

&lt;h2 id=&#34;hermite-interpolation&#34;&gt;Hermite Interpolation&lt;/h2&gt;

&lt;p&gt;I find these artifacts unacceptable but I don&amp;rsquo;t want to increase the packet send rate to fix them. Let&amp;rsquo;s see what we can do to make it look better at the same send rate instead. One thing we can try is upgrading to a more accurate interpolation scheme for position, one that interpolates between position samples while considering the linear velocity at each sample point.&lt;/p&gt;

&lt;p&gt;A spline that can be used to perform this interpolation is the &lt;a href=&#34;http://en.wikipedia.org/wiki/Hermite_interpolation&#34;&gt;hermite spline&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Unlike other splines with control points that affect the curve indirectly, the hermite spline is guaranteed to pass through the start and end points while matching the start and end velocities. This means that velocity is smooth across sample points and cubes in the katamari ball tend to rotate around the cube rather than interpolate through it at speed.&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_hermite_interpolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_hermite_interpolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;Above you can see hermite interpolation for position @ 10pps. Bandwidth has increased slightly because we need to include linear velocity with each cube in the snapshot, but we&amp;rsquo;re able to significantly increase the quality at the same send rate. I can no longer see any artifacts. Go back and compare this with the raw, non-interpolated 10pps version. It really is amazing that we&amp;rsquo;re able to reconstruct the simulation with this level of quality at such a low send rate.&lt;/p&gt;

&lt;p&gt;As an aside, I found it was not necessary to perform higher order interpolation for orientation quaternions to get smooth interpolation. This is great because I did a lot of research into exactly interpolating between orientation quaternions with a specified angular velocity at sample points and it seemed difficult. All that was needed to achieve an acceptable result was to switch from linear interpolation + normalize (nlerp) to spherical linear interpolation (slerp) to ensure constant angular speed for orientation interpolation.&lt;/p&gt;

&lt;p&gt;I believe this is because cubes in the simulation tend to have mostly constant angular velocity while in the air and large angular velocity changes occur only discontinuously when collisions occur. It could also be because orientation tends to change slowly while in the air vs. position which changes rapidly relative to the number of pixels affected on screen. Either way, it seems that slerp is good enough and that&amp;rsquo;s great because it means we don&amp;rsquo;t need to send angular velocity in the snapshot.&lt;/p&gt;

&lt;h2 id=&#34;handling-real-world-conditions&#34;&gt;Handling Real World Conditions&lt;/h2&gt;

&lt;p&gt;Now we have to deal with packet loss. After the discussion of UDP vs. TCP in the previous article I&amp;rsquo;m sure you can see why we would never consider sending snapshots over TCP. Snapshots are time critical but unlike inputs in deterministic lockstep snapshots don&amp;rsquo;t need to be reliable. If a snapshot is lost we can just skip past it and interpolate towards a more recent snapshot in the interpolation buffer. We don&amp;rsquo;t ever want to stop and wait for a lost snapshot packet to be resent. This is why you should always use UDP for sending snapshots.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll let you in on a secret. Not only were the linear and hermite interpolation videos above recorded at a send rate of 10 packets per-second, they were also recorded at 5% packet loss with +/- 2 frames of jitter @ 60fps. How I handled packet loss and jitter for those videos is by simply ensuring that snapshots are held in the interpolation buffer for an appropriate amount of time before interpolation.&lt;/p&gt;

&lt;p&gt;My rule of thumb is that the interpolation buffer should have enough delay so that I can lose two packets in a row and still have something to interpolate towards. Experimentally I&amp;rsquo;ve found that the amount of delay that works best at 2-5% packet loss is 3X the packet send rate. At 10 packets per-second this is 300ms. I also need some extra delay to handle jitter, which in my experience is typically only one or two frames @ 60fps, so the interpolation videos above were recorded with a delay of 350ms.&lt;/p&gt;

&lt;p&gt;Adding 350 milliseconds delay seems like a lot. And it is. But, if you try to skimp you end up hitching for 1/10th of a second each time a packet is lost. One technique that people often use to hide the delay added by the interpolation buffer in other areas (such as FPS, flight simulator, racing games and so on) is to use extrapolation. But in my experience, extrapolation doesn&amp;rsquo;t work very well for rigid bodies because their motion is non-linear and unpredictable. Here you can see an extrapolation of 200ms, reducing overall delay from 350 ms to just 150ms:&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_extrapolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/snapshot_interpolation_10pps_extrapolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;Problem is it&amp;rsquo;s just not very good. The reason is that the extrapolation doesn&amp;rsquo;t know anything about the physics simulation. Extrapolation doesn&amp;rsquo;t know about collision with the floor so cubes extrapolate down through the floor and then spring back up to correct. Prediction doesn&amp;rsquo;t know about the spring force holding the player cube up in the air so it the cube moves slower initially upwards than it should and has to snap to catch up. It also doesn&amp;rsquo;t know anything about collision and how collision response works, so the cube rolling across the floor and other cubes are also mispredicted. Finally, if you watch the katamari ball you&amp;rsquo;ll see that the extrapolation predicts the attached cubes as continuing to move along their tangent velocity when they should rotate with the player cube.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;You could conceivably spend a great deal of time to improve the quality of this extrapolation and make it aware of various movement modes for the cubes. You could take each cube and make sure that at minimum the cube doesn&amp;rsquo;t go through the floor. You could add some approximate collision detection or response using bounding spheres between cubes. You could even take the cubes in the katamari ball and make them predict motion to rotate around with the player cube.&lt;/p&gt;

&lt;p&gt;But even if you do all this there will still be misprediction because you simply can&amp;rsquo;t accurately match a physics simulation with an approximation. If your simulation is mostly linear motion, eg. fast moving planes, boats, space ships &amp;ndash; you may find that a simple extrapolation works well for short time periods (50-250ms or so), but in my experience as soon as objects start colliding with other non-stationary objects, extrapolation starts to break down.&lt;/p&gt;

&lt;p&gt;How can we reduce the amount of delay added for interpolation? 350ms still seems unacceptable and we can&amp;rsquo;t use extrapolation to reduce this delay without adding a lot of inaccuracy. The solution is simple: &lt;em&gt;increase the send rate!&lt;/em&gt; If we send 30 snapshots per-second we can get the same amount of packet loss protection with a delay of 150ms. 60 packets per-second needs only 85ms.&lt;/p&gt;

&lt;p&gt;In order to increase the send rate we&amp;rsquo;re going to need some pretty good bandwidth optimizations. But don&amp;rsquo;t worry, there&amp;rsquo;s a &lt;em&gt;lot&lt;/em&gt; we can do to optimize bandwidth. So much so that there was too much stuff to fit in this article and I had to insert an extra unplanned article just to cover all of it!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NEXT ARTICLE&lt;/strong&gt;: &lt;a href=&#34;http://gafferongames.com/networked-physics/snapshot-compression/&#34;&gt;Snapshot Compression&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deterministic Lockstep</title>
      <link>http://173.255.195.190/gafferongames/post/deterministic_lockstep/</link>
      <pubDate>Sat, 29 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://173.255.195.190/gafferongames/post/deterministic_lockstep/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;http://173.255.195.190/gafferongames/about&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;http://173.255.195.190/gafferongames/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In this article series we&amp;rsquo;re exploring different ways to network a physics simulation. In this article specifically, we&amp;rsquo;re going to network a physics simulation using deterministic lockstep.&lt;/p&gt;

&lt;p&gt;Deterministic lockstep is a method of networking a system from one computer to another by sending only the &lt;em&gt;inputs&lt;/em&gt; that control that system, rather than the &lt;em&gt;state&lt;/em&gt; of that system. In the context of networking a physics simulation, this means we send across a small amount of input, while avoiding sending state like position, orientation, linear velocity and angular velocity per-object.&lt;/p&gt;

&lt;p&gt;The benefit is that bandwidth is proportional to the size of the input, not the number of objects in the simulation. Yes, with deterministic lockstep you can network a physics simulation of one million objects with the same bandwidth as just one.&lt;/p&gt;

&lt;p&gt;While this sounds great in theory, in practice it&amp;rsquo;s difficult to implement deterministic lockstep because most physics simulations are not deterministic. Differences in floating point behavior between compilers, OS&amp;rsquo;s and even instruction sets make it almost impossible to guarantee determinism for floating point calculations.&lt;/p&gt;

&lt;h2 id=&#34;determinism&#34;&gt;Determinism&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s drill down a bit more into this concept of determinism.&lt;/p&gt;

&lt;p&gt;In this context, determinism means that given the same initial condition and the same set of inputs your simulation gives exactly the same result. And I do mean &lt;em&gt;exactly&lt;/em&gt; the same result.&lt;/p&gt;

&lt;p&gt;Not close. Not near enough. &lt;strong&gt;Exactly the same&lt;/strong&gt;. Exact down to the bit-level. So exact, you could take a checksum of your entire physics state at the end of each frame and it would be identical.&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_desync.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_desync.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;Above you can see a simulation that is &lt;em&gt;almost&lt;/em&gt; deterministic. The simulation on the left is controlled by the player. The simulation on the right has exactly the same inputs applied with a two second delay starting from the same initial condition. Both simulations step forward with the same delta time (a necessary precondition to ensure exactly the same result) and both simulations apply the same inputs. Notice how after the smallest divergence the simulation gets further and further out of sync. This simulation is &lt;strong&gt;non-deterministic&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s going on is that the physics engine I&amp;rsquo;m using (&lt;a href=&#34;http://opende.org&#34;&gt;Open Dynamics Engine&lt;/a&gt;) uses a random number generator inside its solver to randomize the order of constraint processing to improve stability. It&amp;rsquo;s open source. Take a look and see! Unfortunately this breaks determinism because the simulation on the left processes constraints in a different order to the simulation on the right, leading to slightly different results.&lt;/p&gt;

&lt;p&gt;Luckily all that is required to make ODE deterministic on the same machine, with the same complied binary and on the same OS (is that enough qualifications?) is to set its internal random seed to the current frame number before running the simulation via dSetRandomSeed. Once this is done ODE gives exactly the same result and the left and right simulations stay in sync.&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;And now a word of warning. Even though the simulation above is deterministic on the same machine, that does &lt;em&gt;not&lt;/em&gt; necessarily mean it would also be deterministic across different compilers, a different OS or different machine architectures (eg. PowerPC vs. Intel). In fact, it&amp;rsquo;s probably not even deterministic between debug and release builds due to floating point optimizations.&lt;/p&gt;

&lt;p&gt;Floating point determinism is a complicated subject and there&amp;rsquo;s no silver bullet.&lt;/p&gt;

&lt;p&gt;For more information please refer to this &lt;a href=&#34;http://gafferongames.com/networking-for-game-programmers/floating-point-determinism/&#34;&gt;article&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;networking-inputs&#34;&gt;Networking Inputs&lt;/h2&gt;

&lt;p&gt;Now that I have impressed upon you the complexity of perfect determinism, let&amp;rsquo;s get down to implementation, assuming your simulation is in fact deterministic.&lt;/p&gt;

&lt;p&gt;You may wonder what the input in our example simulation is and how we should network it. Well, our example physics simulation is driven by keyboard input: arrow keys apply forces to make the player cube move, holding space lifts the cube up and blows other cubes around, and holding &amp;lsquo;z&amp;rsquo; enables katamari mode.&lt;/p&gt;

&lt;p&gt;But how can we network these inputs? Must we send the entire state of the keyboard? No. It&amp;rsquo;s not necessary to send the entire keyboard state, only the state of the keys that affect the simulation. What about key press and release events then? No. This is also not a good strategy. We need to ensure that exactly the same input is applied on the right side, at exactly the same time, so we can&amp;rsquo;t just send &amp;lsquo;key pressed&amp;rsquo;, and &amp;lsquo;key released&amp;rsquo; events over TCP.&lt;/p&gt;

&lt;p&gt;What we do instead is represent the input with a struct and at the beginning of each simulation frame on the left side, sample this struct from the keyboard:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    struct Input
    {
        bool left;
        bool right;
        bool up;
        bool down;
        bool space;
        bool z;
    };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we send that input from the left simulation to the right simulation in a way that the simulation on the right side knows that the input belongs to frame n.&lt;/p&gt;

&lt;p&gt;And here&amp;rsquo;s the key part: the simulation on the right can only simulate frame n when it has the input for that frame. If it doesn&amp;rsquo;t have the input, it has to wait.&lt;/p&gt;

&lt;p&gt;For example, if you were sending across using TCP you could simply send the inputs and nothing else, and on the other side you could read the packets coming in, and each input received corresponds to one frame for the simulation to step forward. If no input arrives for a given render frame, the right side can&amp;rsquo;t advance forward, it has to wait for the next input to arrive.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s say you&amp;rsquo;re using TCP, you&amp;rsquo;ve disabled &lt;a href=&#34;http://en.wikipedia.org/wiki/Nagle&#39;s_algorithm&#34;&gt;Nagle&amp;rsquo;s Algorithm&lt;/a&gt;, and you&amp;rsquo;re sending inputs from the left to the right simulation once per-frame (60 times per-second).&lt;/p&gt;

&lt;p&gt;Here it gets a little complicated. Since we can&amp;rsquo;t simulate forward unless we have the input for the next frame, it&amp;rsquo;s not enough to just take whatever inputs arrive over the network and then run the simulation on inputs as they arrive because the result would be very jittery. Data sent across the network at 60HZ doesn&amp;rsquo;t typically arrive nicely spaced, 1/60th of a second between each packet.&lt;/p&gt;

&lt;p&gt;If you want this sort of behavior, you have to implement it yourself.&lt;/p&gt;

&lt;h2 id=&#34;playout-delay-buffer&#34;&gt;Playout Delay Buffer&lt;/h2&gt;

&lt;p&gt;Such a device is called a playout delay buffer.&lt;/p&gt;

&lt;p&gt;Unfortunately, the subject of playout delay buffers is a patent minefield. I would not advise searching for &amp;ldquo;playout delay buffer&amp;rdquo; or &amp;ldquo;adaptive playout delay&amp;rdquo; while at work. But in short, what you want to do is buffer packets for a short amount of time so they &lt;em&gt;appear&lt;/em&gt; to be arriving at a steady rate even though in reality they arrive somewhat jittered.&lt;/p&gt;

&lt;p&gt;What you&amp;rsquo;re doing here is similar to what Netflix does when you stream a video. You pause a little bit initially so you have a buffer in case some packets arrive late and then once the delay has elapsed video frames are presented spaced the correct time apart. If your buffer isn&amp;rsquo;t large enough then the video playback will be hitchy. With deterministic lockstep your simulation behaves exactly the same way: showing hitches when the buffer isn&amp;rsquo;t large enough to smooth out the jitter. Of course, the cost of increasing the buffer size is additional latency, so you can&amp;rsquo;t just buffer your way out of all problems. At some point the user says enough! That&amp;rsquo;s too much latency added. No sir, I will &lt;em&gt;not&lt;/em&gt; play your game with 1 second of extra delay :)&lt;/p&gt;

&lt;p&gt;My playout delay buffer implementation is really simple. You add inputs to it indexed by frame, and when the very first input is received, it stores the current local time on the receiver machine and from that point on delivers packets assuming they should play at that time + 100ms. You&amp;rsquo;ll likely need to something more complex for a real world situation, perhaps something that handles clock drift, and detecting when the simulation should slightly speed up or slow down to maintain a nice amount of buffering safety (being &amp;ldquo;adaptive&amp;rdquo;) while minimizing overall latency, but this is reasonably complicated and probably worth an article in itself.&lt;/p&gt;

&lt;p&gt;The goal is that under average conditions the playout delay buffer provides a steady stream of inputs for frame n, n+1, n+2 and so on, nicely spaced 1/60th of a second apart with no drama. In the worst case the time arrives for frame n and the input hasn&amp;rsquo;t arrived yet it returns null and the simulation is forced to wait. If packets get bunched up and delivered late, it&amp;rsquo;s possibly to have multiple inputs ready to dequeue per-frame. In this case I limit to 4 simulated frames per-render frame so the simulation has a chance to catch up, but doesn&amp;rsquo;t simulate for so long that it falls further behind, aka. the &amp;ldquo;spiral of death&amp;rdquo;.&lt;/p&gt;

&lt;h2 id=&#34;is-tcp-good-enough&#34;&gt;Is TCP good enough?&lt;/h2&gt;

&lt;p&gt;Using this playout buffer strategy and sending inputs across TCP we ensure that all inputs arrive reliably and in-order. This is convenient, and after all, TCP is designed for exactly this situation: reliable-ordered data.&lt;/p&gt;

&lt;p&gt;In fact, It&amp;rsquo;s a common thing out there on the Internet for pundits to say stuff like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.reddit.com/r/gamedev/comments/1tvbe0/is_it_just_me_or_is_networking_really_hard/&#34;&gt;If you need reliable-ordered, you can&amp;rsquo;t do better than TCP!&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://thoughtstreams.io/glyph/your-game-doesnt-need-udp-yet/&#34;&gt;Your game doesn&amp;rsquo;t need UDP (yet)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But I&amp;rsquo;m here to tell you this kind of thinking is &lt;u&gt;&lt;b&gt;dead wrong&lt;/b&gt;&lt;/u&gt;.&lt;/p&gt;

&lt;video autoplay preload=&#34;auto&#34; loop=&#34;true&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_tcp_100ms_1pc.mp4&#34; type=&#34;video/mp4&#34;/&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_tcp_100ms_1pc.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;Above you can see the simulation networked using deterministic lockstep over TCP at 100ms latency and 1% packet loss. If you look closely on the right side you can see hitches every few seconds. What&amp;rsquo;s happening here is that each time a packet is lost, TCP has to wait RTT*2 while it is resent (actually it can be much worse, but I&amp;rsquo;m being generous&amp;hellip;). The hitches happen because with deterministic lockstep the right simulation can&amp;rsquo;t simulate frame n without input n, so it has to pause to wait for input n to be resent!&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s not all. It gets significantly worse as latency and packet loss increase. Here is the same simulation networked using deterministic lockstep over TCP at 250ms latency and 5% packet loss:&lt;/p&gt;

&lt;video autoplay preload=&#34;auto&#34; loop=&#34;true&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_tcp_250ms_5pc.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_tcp_250ms_5pc.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;Now I will concede that if you have no packet loss and/or a very small amount of latency then you very well may get acceptable results with TCP. But please be aware that if you use TCP to send time critical data it degrades &lt;em&gt;&lt;u&gt;terribly&lt;/u&gt;&lt;/em&gt; as packet loss and latency increase.&lt;/p&gt;

&lt;h2 id=&#34;can-we-do-better-than-tcp&#34;&gt;Can we do better than TCP?&lt;/h2&gt;

&lt;p&gt;Can we beat TCP at its own game. Reliable-ordered delivery?&lt;/p&gt;

&lt;p&gt;The answer is an emphatic &lt;b&gt;YES&lt;/b&gt;. But &lt;em&gt;only&lt;/em&gt; if we change the rules of the game.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the trick. We need to ensure that all inputs arrive reliably and in order. But if we send inputs in UDP packets, some of those packets will be lost. What if, instead of detecting packet loss after the fact and resending lost packets, we redundantly include &lt;em&gt;all inputs&lt;/em&gt; in each UDP packet until we know for sure the other side has received them?&lt;/p&gt;

&lt;p&gt;Inputs are very small (6 bits). Let&amp;rsquo;s say we&amp;rsquo;re sending 60 inputs per-second (60fps simulation) and round trip time we know is going the be somewhere in 30-250ms range. Let&amp;rsquo;s say just for fun that it could be up to 2 seconds worst case and at this point we&amp;rsquo;ll time out the connection (screw that guy). This means that on average we only need to include between 2-15 frames of input and worst case we&amp;rsquo;ll need 120 inputs. Worst case is 120*6 = 720 bits. That&amp;rsquo;s only 90 bytes of input! That&amp;rsquo;s totally reasonable.&lt;/p&gt;

&lt;p&gt;We can do even better. It&amp;rsquo;s not common for inputs to change every frame. What if when we send our packet instead we start with the sequence number of the most recent input, and the 6 bits of the first (oldest) input, and the number of un-acked inputs. Then as we iterate across these inputs to write them to the packet we can write a single bit (1) if the next input is different to the previous, and (0) if the input is the same. So if the input is different from the previous frame we write 7 bits (rare). If the input is identical we write just one (common). Where inputs change infrequently this is a big win and in the worst case this really isn&amp;rsquo;t that bad. 120 bits of extra data sent. Just 15 bytes overhead worst case.&lt;/p&gt;

&lt;p&gt;Of course another packet is required from the right simulation to the left so the left side knows which inputs have been received. Each frame the right simulation reads input packets from the network before adding them to the playout delay buffer and keeps track of the most recent input it has received and sends this back to the left as an &amp;ldquo;ack&amp;rdquo; or acknowledgment for inputs.&lt;/p&gt;

&lt;p&gt;When the left side receives this ack it discards any inputs older than the most recent received input. This way we have only a small number of inputs in flight proportional to the round trip time between the two simulations.&lt;/p&gt;

&lt;h2 id=&#34;flawless-victory&#34;&gt;Flawless Victory&lt;/h2&gt;

&lt;p&gt;We have beaten TCP by changing the rules of the game.&lt;/p&gt;

&lt;p&gt;Instead of &amp;ldquo;implementing 95% of TCP on top of UDP&amp;rdquo; we have implemented something &lt;em&gt;totally different&lt;/em&gt; and better suited to our requirements. A protocol that redundantly sends inputs because we know they are small, so we never have to wait for retransmission.&lt;/p&gt;

&lt;p&gt;So exactly how much better is this approach than sending inputs over TCP?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look&amp;hellip;&lt;/p&gt;

&lt;video autoplay preload=&#34;auto&#34; loop=&#34;true&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_udp_2sec_25pc.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/deterministic_lockstep_udp_2sec_25pc.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;

&lt;p&gt;The video above shows deterministic lockstep synchronized over UDP using this technique with &lt;u&gt;2 seconds&lt;/u&gt; of latency and &lt;u&gt;25% packet loss&lt;/u&gt;. Imagine how awful TCP would look under these conditions.&lt;/p&gt;

&lt;p&gt;So in conclusion, even where TCP should have the most advantage, in the only networking model I&amp;rsquo;ll present to you in this article series that relies on reliable-ordered data, we can easily beat it with a simple protocol sent over UDP.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Physics Simulation</title>
      <link>http://173.255.195.190/gafferongames/post/the_physics_simulation/</link>
      <pubDate>Fri, 28 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://173.255.195.190/gafferongames/post/the_physics_simulation/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;http://173.255.195.190/gafferongames/about&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to the first article in &lt;strong&gt;&lt;a href=&#34;http://173.255.195.190/gafferongames/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In this article series we&amp;rsquo;re going to network a physics simulation three different ways: deterministic lockstep, snapshot interpolation and state synchronization.&lt;/p&gt;

&lt;p&gt;But before we get to this, lets spend some time exploring the physics simulation weâre going to network.&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cube.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cube.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Here Iâve setup a simple simulation of a cube in the open source physics engine &lt;a href=&#34;http://www.ode.org&#34;&gt;ODE&lt;/a&gt;. The player moves around by applying forces at its center of mass. The physics simulation takes this linear motion and calculates friction as the cube collides with the ground, inducing a rolling and tumbling motion.&lt;/p&gt;

&lt;p&gt;This tumbling is why I chose a cube instead a sphere. I &lt;em&gt;want&lt;/em&gt; this complex, unpredictable motion because rigid bodies in general move in interesting ways according to their shape. Itâs simply not possible to accurately predict the motion of a rigid body with a linear extrapolation or the ballistic equations of motion.&lt;/p&gt;

&lt;p&gt;If you want to know where a rigid body is at a future time, you have to run the whole physics simulation: dynamics, collision detection, collision response and friction in order to find out!&lt;/p&gt;

&lt;h2 id=&#34;an-interactive-world&#34;&gt;An Interactive World&lt;/h2&gt;

&lt;p&gt;Networking a physics simulation is easy if there is only one object interacting with a static world. It starts to get interesting when the player interacts with other physically simulated objects, &lt;em&gt;especially&lt;/em&gt; when those objects push back and affect the motion of the player.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s add some more cubes to the simulation:&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cubes_roll.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cubes_roll.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;Notice when the player interacts with a cube it turns red. When that cube comes to rest it turns back to grey (non-interacting). Interactions arenât just direct. Red cubes hit by the player turn other cubes they touch red as well. This way player interactions fan-out covering all affected objects.&lt;/p&gt;

&lt;p&gt;While itâs cool to roll around and interact with other cubes, what I really wanted was a way to push &lt;em&gt;lots&lt;/em&gt; of cubes around. What I came up with is this:&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cubes_blow.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cubes_blow.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;To implement this I raycast to find the intersection with the ground below the center of mass of the player cube, then apply a spring force (see &lt;a href=&#34;https://en.wikipedia.org/wiki/Hooke%27s_law&#34;&gt;Hookeâs law&lt;/a&gt;) relative to the distance from this point, making the player cube float in the air.&lt;/p&gt;

&lt;p&gt;Then all non-player cubes within a certain distance of that intersection point have a force applied proportional to their distance from this point and away from it, so they are pushed away out of the way like leaves from a leaf blower.&lt;/p&gt;

&lt;h2 id=&#34;a-complicated-case&#34;&gt;A Complicated Case&lt;/h2&gt;

&lt;p&gt;I also wanted a very complex coupled motion between the player and non-player cubes such that the player and the objects its interacting with become one single system, a group of rigid bodies joined together by constraints.&lt;/p&gt;

&lt;p&gt;To implement this I thought it would be cool if the player could roll around and create a ball of cubes, like in one of my favorite games &lt;a href=&#34;https://en.wikipedia.org/wiki/Katamari_Damacy&#34;&gt;Katamari Damacy&lt;/a&gt;.&lt;/p&gt;

&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cubes_katamari.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://173.255.195.190/gafferongames/video/networked_physics/the_physics_simulation_cubes_katamari.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;To implement this effect cubes within a certain distance of the player have a force applied towards the center of the cube. These cubes remain physically simulated while in the katamari ball, they are not just âstuckâ to the player like in the original game.&lt;/p&gt;

&lt;p&gt;This means that the cubes in the katamari are continually pushing and interacting with each other and the player cube via collision constraints.&lt;/p&gt;

&lt;p&gt;This is a very difficult situation for networked physics.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>